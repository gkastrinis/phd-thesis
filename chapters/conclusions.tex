\chapter{Conclusions and Future Work}
\label{chapter:conclusions}
\epigraph{Everythingâ€™s got to end sometime. Otherwise nothing would ever get started.}{\textit{The 11th Doctor} - Doctor Who}

In this final chapter, we assess our initial thesis and conclude, while also considering interesting directions for future work.

The first part of our dissertation thesis states that it is possible to obtain \emph{precise} yet \emph{scalable} static pointer analysis algorithms by carefully employing different policies for different parts of the program.

In Chapter~\ref{chapter:hybrid}, we presented an analysis that combines call-site sensitivity and object sensitivity in a non-trivial manner. Instead of keeping both context flavors at all times, we alter an object-sensitive analysis so that it uses call-site sensitive elements in places where it would be more beneficial (e.g., in handling static call invocations). We show that this approach not only bears the precision benefits of combining the two flavors, but also avoids incurring the accumulated cost. For instance, in our experiments we observed an average speedup of \best{1.53x} alongside a more precise analysis. Additionally, we provide a concise way to formulate variations of both a uniform and a selective approach, in order to experiment with different flavor combinations and context depths.

In Chapter~\ref{chapter:introspective}, \emph{introspective analysis} examines another approach to a precise and scalable analysis. Our two-phase algorithm allows for a cheap, yet imprecise, analysis to run as a first step in order to gather crucial metrics that gauge the potential effect that a more precise context might have on various program elements (e.g., object allocations or method invocations). Subsequently, a more precise analysis is applied only on those elements that were deemed to benefit from the additional precision, without at the same time imposing a significant penalty on performance.

We employ various heuristics for deciding which program elements are worth the extra effort of a more precise handling, and show experimentally that although it is not a ``first line of defense'' kind of analysis, introspective analysis can be a valuable ``if all else fails'' alternative. Users can ``dial-in'' scalability (by parametrizing the heuristics that decide which elements are to be handled more accurately) to the exact level required, without having to sacrifice a significant fraction of precision. Previously hopeless analyses now become feasible. For instance, a variation of our analysis scales to all but one benchmark in under \best{20 minutes}, while keeping about \nums{2/3} of the precision gains that a more precise, yet ``heavy'' analysis would achieve.

The second part of our thesis stipulates that analyses can be designed to offer novel, strong guarantees on the soundness of results, but only for specific parts of the program.

In Chapters~\ref{chapter:must-logic} and \ref{chapter:must-data}, we model an instance of a \emph{must}-alias analysis, a conservative analysis that \emph{under}-approximates results but can guarantee that what is reported is actually correct. The nature of the analysis makes it valuable for compiler optimizations, program understanding, the improvement of bug detectors, and even as an internal component in more sophisticated analyses.

The analysis we present is minimal, yet it models core features in a handful of declarative rules. This makes reasoning about the analysis semantics less arduous. For instance, this partially led to the insights that called for the introduction of a specialized data structure in Chapter~\ref{chapter:must-data}. Additionally, the analysis highlights a non-conventional use of context; instead of a beneficial add-on, it is a crucial part of the analysis that guarantees that interprocedural propagation of information remains valid. Another benefit stemming from our analysis is its \emph{incrementality}. Soundness is not compromised if only a portion of the program-under-analysis or its libraries are available; only completeness. The availability of more code simply implies more inferences for our analysis. Precomputed facts are guaranteed to always hold, independently of what new parts of the code are analyzed in the future.

Following our insights from Chapter~\ref{chapter:must-logic}, we introduce a specialized data structure that exploits the fact that must-alias sets are equivalence classes, and as such there is no need to explicitly compute each alias pair. This ``laziness'' in computation is further exploited to implicitly encode the extension of alias information to longer access paths. Our data structure is in the form of a alias graph that abstractly represents local variables and the heap. Nodes (abstract objects) are alias classes, edges are field-points-to relationships.

In a complementary fashion, we describe all the algorithms on our alias graph required by a must-alias analysis. We implemented our data structure both imperatively, in Java, with destructive updates, and purely functionally, in Datalog. Both implementations yield large performance improvements compared to an explicit representation of all alias pairs. The imperative version achieves a speedup of up to \best{two orders} of magnitude, with the declarative implementation nearly matching it in most cases. As a result, the running time of a realistic must-alias analysis becomes small---\best{a few tens of seconds} for large benchmarks and the full Java library.

Finally, in Chapter~\ref{chapter:defensive}, we conclude our contributions with another conservative and \emph{fully sound} may-analysis. Soundness in our \emph{defensive analysis} means that it has to (correctly) over-approximate all concrete executions. This proves quite challenging in practice due to code that cannot be analyzed (e.g., dynamically generated code, or native code) or dynamic language features (e.g., reflection).

The analysis employs a different logical approach from past analyses, in order to successfully distinguish ``safe'' inferences (i.e., certain to not be affected by unknown code, and hence correct).  In essence, our analysis produces inferences only when these are guaranteed to hold because of existing code, and cannot possibly be violated by other, unknown code. In our effort to implement defensive analysis in a realistic package, we found that \emph{laziness} is an essential feature---the analysis cannot scale without it for real-world programs.

Experiments show that the analysis is efficient, leveraging its lazy representation of points-to sets. As a result, it can be made precise, beyond the limits of standard whole-program points-to analyses (e.g., achieving a 5-call-site-sensitive and flow-sensitive analysis). The analysis is also modular since it can be applied to any subset of the program. Although quite defensive, the analysis yields useful coverage over large Java benchmarks. In our experimental setup, the analysis computes guaranteed over-approximate points-to set for \nums{34-74\%} of the local variables of a conventional unsound analysis. Similar effectiveness is achieved for other metrics, again with actionable, guaranteed-sound outcomes.


To summarize, we advocate that modern, sophisticated, static pointer analyses need not make a sacrifice over precision or scalability, to achieve the other. Both properties are achievable with appropriate tuning and design choices, for different parts of the program. Complementary, it is possible for analyses to compute results alongside with strong soundness guarantees, again focusing at specific parts of the program. To conclude, a static pointer analysis algorithm doesn't have to use a one-size-fits-all handling of every language feature and program point, but instead it is favorable to methodically differentiate its policies for different parts of the code, towards different desired outcomes.


\section{Future Work}

Finally, we will discuss some interesting future directions to tackle existing limitations of our approaches.

\paragraph{Hybrid-Context Sensitivity.}
Our approach in hybrid analysis showed that it is beneficial to combine different kind of context flavors when dealing with different program elements. Our work focused on the handling of static call invocations, and also only examined two alternatives of contexts (in a given analysis). Future work can explore the existence of other language features that would benefit from a different context, as well as the potential variation of context depth itself. An example of an interesting program element that might benefit from a different context is the handling of collections (e.g., lists, maps, sets, etc.) that the Java library offers. Maybe an analysis can keep its context depth limited in ``normal'' code, and push for higher precision (via allowing for more context depth) when analyzing the code of a collection class. 

\paragraph{Introspective Analysis.}
Future work in the context of our introspective analysis, first includes the examination of more sophisticated and highly tuned heuristics. Our heuristics, were good enough to gauge potential program elements that would benefit from a more precise handling, but there is always room for improvement. Especially, in picking more fined-tuned values for the parameters of each heuristic, one might examine an approach in which the actual values depend on other metrics specific to the program at hand. For instance, whether the program is heavy on reflection or the use of static call, etc. Another potential direction to explore is whether a more sophisticated strategy in the refinement steps is favorable. In our current implementation, the first step is a cheap and crude analysis, and the second step is the fully-fledged precise analysis. Maybe a multi-staged approach that slowly increases precision, while in interleaved steps re-evaluates which program elements need more accurate handling, bears significant precision and scalability gains.

\paragraph{Must-Alias Analysis.}
The main venue of exploration in our must-alias analysis is that of expanding our minimal model. The presented model captures the core elements that an analysis of this nature has to handle, but still misses many more language features. Improvements towards that end will server in inferring more alias pairs, thus increasing the analysis coverage. An additional direction, is that of modeling specific library code that is too hard to manually analyze but could potentially be crucial in improving the analysis reasoning. For example, such modeling might include important ``low-level'' methods such as \code{equals} or \code{clone} that have clear and ``safe'' semantics.

\paragraph{Defensive Points-To Analysis.}
Finally, regarding our last contribution, future work includes directions similar to those of our must-alias analysis. A potential modeling of crucial methods, such as access to collections and core native functions could significantly increase the coverage of the analysis. Those methods are hard to automatically analyze in a sound manner, but have clear semantics offered by the language specification. Furthermore, another future approach includes the modeling of a more refined concurrency model. The simplified concurrency model we presented allowed us to describe the analysis in its purest form, starting from a sound basis, with the potential of adding to it conservatively.